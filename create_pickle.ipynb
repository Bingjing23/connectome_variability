{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0c07f6-c293-4e8a-a409-263f3a59bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, IntSlider\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c277dba-6024-41c5-a8c1-c82addf37e3e",
   "metadata": {},
   "source": [
    "subject_matrices.pkl contains all the individual correlation matrixes for the 100 iterations\n",
    "\n",
    "subject_statistics.pkl contains the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26318223-a436-4535-91dd-7fdcc5152e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matrices(zip_path, extract_dir):\n",
    "    '''\n",
    "    Function to extract and read TSV files from one ZIP file\n",
    "    We have 12 matrixes per zip\n",
    "    We return a dictionary that organizes the matrixes per condition\n",
    "    '''\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    \n",
    "    matrices = defaultdict(list)\n",
    "    \n",
    "    for root, dirs, files in os.walk(extract_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"_desc-correlation_matrix.tsv\"):\n",
    "                category = file.split(\"feature-\")[1].split(\"CorrMatrix\")[0]\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    matrix = np.loadtxt(file_path, delimiter=\"\\t\")\n",
    "                    if np.issubdtype(matrix.dtype, np.number):\n",
    "                        matrices[category].append(matrix)\n",
    "                    else:\n",
    "                        print(f\"Non-numeric data found in file: {file_path}\")\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "    return matrices\n",
    "\n",
    "\n",
    "def compute_statistics(matrices):\n",
    "    '''\n",
    "    Function to compute averages and standard deviations for each category.\n",
    "    '''\n",
    "    averages = {}\n",
    "    std_devs = {}\n",
    "    counts = {}\n",
    "    worst_cases = {}\n",
    "    for category, matrix_list in matrices.items():\n",
    "        try:\n",
    "            matrix_array = np.array(matrix_list)\n",
    "            avg_matrix = np.nanmean(matrix_array, axis=0)  # Compute the average matrix from list\n",
    "            std_matrix = np.nanstd(matrix_array, axis=0)  # Compute the standard deviation matrix from list\n",
    "            worst_case_matrix = np.abs(np.nanmax(matrix_array, axis=0) - np.nanmin(matrix_array, axis=0))  # Compute worst-case scenario\n",
    "            averages[category] = avg_matrix\n",
    "            std_devs[category] = std_matrix\n",
    "            worst_cases[category] = worst_case_matrix\n",
    "            counts[category] = len(matrix_list)\n",
    "        except TypeError as e:\n",
    "            print(f\"Error computing statistics for category {category}: {e}\")\n",
    "            print(f\"Matrix list: {matrix_list}\")\n",
    "            \n",
    "    return averages, std_devs, worst_cases, counts\n",
    "\n",
    "def process_all(zip_dir, extract_dir):\n",
    "    all_subjects = {}\n",
    "    \n",
    "    for zip_file in os.listdir(zip_dir):\n",
    "        if zip_file.endswith(\".zip\"):\n",
    "            zip_path = os.path.join(zip_dir, zip_file)\n",
    "            subject_id = zip_file.split(\"_\")[1]  # Assuming subject ID is the second part of the zip file name\n",
    "            matrices = extract_matrices(zip_path, extract_dir)\n",
    "            # print(f\"Processed {subject_id} from {zip_file}\")\n",
    "            \n",
    "            if subject_id not in all_subjects:\n",
    "                all_subjects[subject_id] = {}\n",
    "            \n",
    "            for category, matrix_list in matrices.items():\n",
    "                if category not in all_subjects[subject_id]:\n",
    "                    all_subjects[subject_id][category] = []\n",
    "                all_subjects[subject_id][category].extend(matrix_list)\n",
    "        \n",
    "            # Clean up extracted files\n",
    "            shutil.rmtree(extract_dir)\n",
    "            os.makedirs(extract_dir, exist_ok=True)\n",
    "        \n",
    "    return all_subjects\n",
    "\n",
    "def aggregate_stats(all_subjects):\n",
    "    '''\n",
    "    For each ROI-to-ROI pair, we compute the average correlation, standard deviations, \n",
    "    worst-case differences, and counts for each subject and category\n",
    "    '''\n",
    "    subject_averages = {}\n",
    "    subject_deviations = {}\n",
    "    subject_worst_cases = {}\n",
    "    subject_counts = {}\n",
    "    for subject_id, categories in all_subjects.items():\n",
    "        averages, std_devs, worst_cases, counts = compute_statistics(categories)\n",
    "        subject_averages[subject_id] = averages\n",
    "        subject_deviations[subject_id] = std_devs\n",
    "        subject_worst_cases[subject_id] = worst_cases\n",
    "        subject_counts[subject_id] = counts\n",
    "\n",
    "    return subject_averages, subject_deviations, subject_worst_cases, subject_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2bead5-8ba6-44d4-a3ad-623fe7dd1917",
   "metadata": {},
   "source": [
    "### 1. Create subject_matrices.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e72acd9a-d329-4be0-85e9-f102ef0074c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects processed: ['sub-9040', 'sub-13192', 'sub-01']\n"
     ]
    }
   ],
   "source": [
    "zip_dir = \"100iterations\" \n",
    "temp_extract_dir = \"100iterations_extracted\"  \n",
    "\n",
    "all_subjects = process_all(zip_dir, temp_extract_dir)\n",
    "print(f\"Subjects processed: {list(all_subjects.keys())}\")\n",
    "\n",
    "with open(\"subject_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_subjects, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83545dc1-72e3-493f-9e52-15b7f374b9d2",
   "metadata": {},
   "source": [
    "### 2. Create subject_stats.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00ea41c-dbfa-4986-bf15-12a41359562c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aggregate_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute averages, standard deviations, worst-case differences, and counts\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m subject_averages, subject_deviations, subject_worst_cases, subject_counts \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_stats\u001b[49m(all_subjects)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the processed data to a pickle file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_to_save \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_averages\u001b[39m\u001b[38;5;124m\"\u001b[39m: subject_averages,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_deviations\u001b[39m\u001b[38;5;124m\"\u001b[39m: subject_deviations,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_worst_cases\u001b[39m\u001b[38;5;124m\"\u001b[39m: subject_worst_cases,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m: subject_counts\n\u001b[1;32m     10\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aggregate_stats' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute averages, standard deviations, worst-case differences, and counts\n",
    "subject_averages, subject_deviations, subject_worst_cases, subject_counts = aggregate_stats(all_subjects)\n",
    "\n",
    "# Save the processed data to a pickle file\n",
    "data_to_save = {\n",
    "    \"subject_averages\": subject_averages,\n",
    "    \"subject_deviations\": subject_deviations,\n",
    "    \"subject_worst_cases\": subject_worst_cases,\n",
    "    \"subject_counts\": subject_counts\n",
    "}\n",
    "\n",
    "with open(\"subject_statistics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17d736-32f7-4f24-abe7-abce44cffdf0",
   "metadata": {},
   "source": [
    "### 3. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4965a7-49ee-42be-9258-caff2a1d29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"subject_matrices.pkl\", \"rb\") as f:\n",
    "    all_subjects = pickle.load(f)\n",
    "\n",
    "with open(\"subject_statistics.pkl\", \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "subject_averages = loaded_data[\"subject_averages\"]\n",
    "subject_counts = loaded_data[\"subject_counts\"]\n",
    "subject_avg_deviations = loaded_data[\"subject_deviations\"]\n",
    "subject_worst = loaded_data[\"subject_worst_cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f29743-2922-49ba-ad43-e8bbd6dd3f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['subject_averages', 'subject_deviations', 'subject_worst_cases', 'subject_counts'])\n",
      "dict_keys(['sub-9040', 'sub-13192', 'sub-01'])\n",
      "Subject: sub-9040\n",
      "  Category: TrueComb2\n",
      "  Category: FalseComb5\n",
      "  Category: FalseComb2\n",
      "  Category: TrueComb5\n",
      "  Category: FalseComb3\n",
      "  Category: TrueComb4\n",
      "  Category: TrueComb3\n",
      "  Category: FalseComb4\n",
      "  Category: FalseComb1\n",
      "  Category: TrueComb1\n",
      "  Category: TrueComb0\n",
      "  Category: FalseComb0\n",
      "Subject: sub-13192\n",
      "  Category: TrueComb2\n",
      "  Category: FalseComb1\n",
      "  Category: TrueComb5\n",
      "  Category: FalseComb0\n",
      "  Category: TrueComb4\n",
      "  Category: TrueComb3\n",
      "  Category: FalseComb2\n",
      "  Category: FalseComb5\n",
      "  Category: TrueComb1\n",
      "  Category: FalseComb4\n",
      "  Category: TrueComb0\n",
      "  Category: FalseComb3\n",
      "Subject: sub-01\n",
      "  Category: FalseComb0\n",
      "  Category: TrueComb4\n",
      "  Category: TrueComb3\n",
      "  Category: TrueComb2\n",
      "  Category: FalseComb1\n",
      "  Category: TrueComb5\n",
      "  Category: FalseComb4\n",
      "  Category: TrueComb0\n",
      "  Category: FalseComb3\n",
      "  Category: FalseComb2\n",
      "  Category: FalseComb5\n",
      "  Category: TrueComb1\n"
     ]
    }
   ],
   "source": [
    "print(loaded_data.keys())\n",
    "print(subject_averages.keys())\n",
    "\n",
    "#non_normal_cells = data['cells']\n",
    "for subject_id, categories in subject_averages.items():\n",
    "    print(f\"Subject: {subject_id}\")\n",
    "    for category in categories.keys():\n",
    "        print(f\"  Category: {category}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
